{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb88129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7422cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is Z, going into a convolution (c x 100 x 1)\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False), # 100차원의 값을 받아 512차원으로 늘리면서 512x4x4로 변경시켜줌\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # State size. c x 512 x 4 x 4\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # State size. c x 256 x 8 x 8\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # State size. c x 128 x 16 x 16\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # State size. 64 x 32 x 32\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # State size. 3 x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is 3 x 64 x 64\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size. 64 x 32 x 32\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size. 128 x 16 x 16\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size. 256 x 8 x 8\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State size. 512 x 4 x 4\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63df014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generated_images(images, num_images=64):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Generated Images\")\n",
    "    images = vutils.make_grid(images[:num_images], padding=2, normalize=True)\n",
    "    images = np.transpose(images.cpu(), (1, 2, 0))\n",
    "    plt.imshow(images)\n",
    "    plt.show()\n",
    "\n",
    "def save_generated_images(images, num_images, epoch, idx):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Generated Images\")\n",
    "    images = vutils.make_grid(images[:num_images], padding=2, normalize=True)\n",
    "    images = np.transpose(images.cpu(), (1, 2, 0))\n",
    "    # plt.imshow(images)\n",
    "    fname = './output/image_'+str(epoch)+'_'+str(idx)+'.jpg'\n",
    "    plt.imsave(fname, images.numpy())\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c596a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator and the discriminator\n",
    "netG = Generator()\n",
    "netD = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the weights_init function to randomly initialize all weights\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64), # 얼굴이 보통 중간에 있으니 중간을 잘라서 학습하는 것이 좋음\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)), # 데이터의 범위를 [-1,1]로 지정 \n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='./data/celeba', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f51271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "netG.to(device)\n",
    "netD.to(device)\n",
    "\n",
    "criterion = nn.BCELoss() # 이진 크로스 엔트로피 사용\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "num_epochs = 10  # For demonstration purposes; increase for better results\n",
    "\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device=device)         # intermediate visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # Update Discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        netD.zero_grad()\n",
    "        real_data = data[0].to(device)\n",
    "        batch_size = real_data.size(0)\n",
    "        real_label = torch.full((batch_size,), 1, dtype=torch.float, device=device) # full-> 입력된 para size와 동일한 텐서 생성하고 지정한 값으로 채움\n",
    "        fake_label = torch.full((batch_size,), 0, dtype=torch.float, device=device)\n",
    "\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_data).view(-1)\n",
    "        errD_real = criterion(output, real_label)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # Generate fake image batch with G\n",
    "        # noise = torch.randn(batch_size, 100, device=device)\n",
    "        noise = torch.randn(batch_size, 100, 1,1, device=device)\n",
    "        fake_data = netG(noise)\n",
    "        output = netD(fake_data.detach()).view(-1)\n",
    "\n",
    "        # Calculate D's loss on the fake batch\n",
    "        errD_fake = criterion(output, fake_label)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        # Add the gradients from the real and fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update Generator: maximize log(D(G(z)))\n",
    "        netG.zero_grad()\n",
    "        output = netD(fake_data).view(-1)\n",
    "        errG = criterion(output, real_label)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader), errD.item(), errG.item()))\n",
    "            # fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "            fake_images = netG(fixed_noise)\n",
    "            save_generated_images(fake_images, 64, epoch=epoch, idx=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function\n",
    "fake_images = netG(fixed_noise)\n",
    "show_generated_images(fake_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf638c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
