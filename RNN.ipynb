{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2eafd7b-58bd-4dbf-8ff2-597cc4c2170d",
   "metadata": {},
   "source": [
    "### 훈민정음 서문을 학습하는 RNN\n",
    "훈민정음 서문을 잘 학습했다면 서문의 첫 단어를 입력하면 다음 문장들을 자동으로 출력하는 Model구현이 Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e136fb-4316-496f-8b7b-d0314f6e1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re # 보통 문자열을 다루기 \u001f위해서 import하는 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04e07e8-d016-4c99-890d-f738840e4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = \"나라의 말이 중국과 달라 문자와 서로  통하지 아니하기에 이런 까닭으로 어리석은 백성이 이르고자 할 바가 있어도 마침내 제 뜻을 \u001d",
    "히 펴지 못할 사람이 많으니라 내가 이를 위해 가엾이 여겨 새로 스물여덟 글자를 만드노니 사람마다 하여 쉬이 익혀 날로 쓰기에 편안케 하고자 할 따름이니라\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374047e6-df15-415a-ac19-c84ae9cc1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data를 RNN이 쉽게 해석하기 위한 전처리 \n",
    "def data_processting(data):\n",
    "    data = re.sub('[^r가-힣]' , ' ' , data) # 한국어만 받아들이겠다 -> 한자나 , 영어등은 배제\n",
    "    tokens = data.split() # 토큰을 이용해서 RNN이 torken by token으로 정의 \n",
    "    vocab = list(set(tokens)) # NLTK가 tokenize 함수가 token화를 시키는 가장 유명한 func\n",
    "    vocab_size = len(vocab) # \n",
    "\n",
    "    word_to_ix = {word : i for  i , word in enumerate(vocab)} # 모든 단어들을 0 ~ 99까지 독립적으로 배당하는 일 -> 숫자로 변경 후 one-hot incoding을 이용해서 벡터화 시킨 후 해당 벡터를 train data로 시용\n",
    "    ix_to_word = {i : word for i , word in enumerate(vocab)} # model이 생성해낸 숫자를 자연어로 변경\n",
    "\n",
    "    return tokens , vocab_size , word_to_ix , ix_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4cf815-7466-487e-bddc-e235f1c597b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN의 3가지의 가중치\n",
    "def init_weights(h_size , vocab_size):\n",
    "    U = np.random.randn(h_size , vocab_size) * 0.01\n",
    "    W = np.random.randn(h_size , h_size) * 0.01\n",
    "    V = np.random.randn(vocab_size , h_size) * 0.01\n",
    "    return U , W , V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b24614eb-f2d5-4127-83f1-82d45ffcf3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedforward function\n",
    "def feedforward(input , targets , hprev):\n",
    "    loss = 0 \n",
    "    xs , hs , ps , ys = {} ,{} ,{} ,{}\n",
    "    hs[-1] : np.copy(hprev)\n",
    "    for i in range(seq_len):\n",
    "        xs[i] = np.zeros((vocab_size  , 1))\n",
    "        xs[i][inputs[i]] = 1 # 각각의 word에 대한 one-hot coding\n",
    "        hs[i] = np.tanh(np.dot(U , xs[i]) + np.dot(W , hs[i - 1])) \n",
    "        ys[i] = np.dot(V , hs[i])\n",
    "        ps[i] = np.exp(ys[i] / np.sum(np.exp(ys[i]))) # softmax 계산\n",
    "        loss += -np.log(ps[i][targets[i] , 0])\n",
    "    return loss ,  ps , hs , xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644d974-d6e3-4229-8d4e-b135e66c3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(ps , hs , xs):\n",
    "\n",
    "    # Backward propagation through time(BPTT)\n",
    "    # 처음에 모든 가중치들을 0으로 설정\n",
    "    dV = np.zeros(V.shape)\n",
    "    dW = np.zeros(W.shape)\n",
    "    dU = np.zeros(U.shape)\n",
    "\n",
    "    for i in range(seq_len)[::-1]:\n",
    "        output = np.zeros((vocab_size , 1))\n",
    "        output[targets[i]] = 1\n",
    "        ps[i] = ps[i] - output.reshape(-1 , 1)\n",
    "        # 매번 i스텝에서 dL / dVi를 구하기\n",
    "        dV_step_i = ps[i] @ (hs[i]).T # (y_hat - y) @ hs.T - for each step\n",
    "\n",
    "        dV = dV + dV_step_i # dL / dVi를 다 더하기 \n",
    "\n",
    "        # 각i 별로 v와 w를 구하기 위해서는 \n",
    "        # 먼저 공통적으로 계산되는 부분을 delta로 해서 계산해두고 \n",
    "        # 그리고 시간을 거슬러 dL/dWij와 dL/dUij를 구한 뒤\n",
    "        # 각각을 합하여 dL/dW 와 dL / dU를 구하고 \n",
    "        # 다시 공통적으로 계산되는 delta를 업데이트 \n",
    "\n",
    "        # i번째 스텝에서 공통적으로 사용될 delta\n",
    "        delta_recent = (V.T @ ps[i]) * (1 - hs[i] ** 2)\n",
    "\n",
    "        # 시간을 거슬러 올라가서 dL/dW 와 dL/dU를 구함\n",
    "        for j in range(i + 1)[::-1]:\n",
    "            dW_ij = delta_recent @ hs[j - 1].T\n",
    "\n",
    "            dW = dW + dW_ij\n",
    "\n",
    "\n",
    "            dU_ij = delta_recent @ xs[j].reshape(1,  -1)\n",
    "            dU = dU + dU_ij\n",
    "\n",
    "            # 그리고 다음\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
